数据提取对象: all
#maxlength= 1651
#maxlength= 1335
normal数据: 1 2 8 4 7 4 7 , 4 9 7 2 , 1 , 1 2 8 9 7 1 9 , 2 , 5 6 5 5 8 0 , 7 1 9 1 6 7 , 2 7 3 , 2 3 8 , 2 , 1 2 2 Z B j 5 S o G M r s Z e 3 v g A r v 7 i F K 2 q j K D Q Z P g , 1 C i N z v 1 v H k P r P f s c T 7 6 2 a s k P G Z Q T 5 L W i b g , 1 A X 4 n K 2 5 a b X 9 n D t Y M E V U A a 5 R i 8 5 Q A q Y E E p , 6 f 7 7 f 1 4 1 e e a 9 9 0 3 c f d e a 1 1 4 8 e 2 b c 3 7 d 5 0 0 5 6 9 6 5 0 9 9 a 6 8 7 9 d 1 5 8 f 5 6 2 b 4 b 9 b f e 2 a , 9 5 d e 1 7 b 2 3 6 8 f 5 3 2 a b b 9 0 2 f 8 4 c 8 e 3 8 5 a 4 2 4 9 f c 2 c 2 3 1 b 5 9 8 2 f b f b 4 1 8 c 2 1 9 a b c d 0 9 , 4 7 3 0 4 4 0 2 2 0 7 d 8 c e f b 2 6 9 8 8 3 c 3 a 1 2 c 1 6 3 a 3 9 1 e 9 b 7 6 2 b f 5 4 4 3 5 3 1 a 1 e 2 8 5 0 e e 6 d a b 3 d f 7 b f 9 1 a a 0 2 2 0 0 7 a c f a 0 5 2 e 7 f d 7 0 b f 3 7 7 b 1 3 d 5 a 1 c f 5 2 0 3 5 2 e 2 9 c e e f 9 8 d 6 d e c 2 a 6 1 8 4 c 3 9 b 3 1 b a a 0 1 2 1 0 3 f 5 6 b b f d 6 9 a a 0 e 1 2 6 4 6 8 c 0 d 9 5 c 2 7 4 9 8 f a 8 2 6 6 9 8 5 2 d 9 5 1 f e 5 b 6 5 d b 1 0 a b 6 e f e 4 5 2 3 , 7 6 a 9 1 4 8 0 7 c c d 2 e a 9 f 2 0 1 8 2 2 c 5 c 6 e 0 d 4 0 8 c b 9 a 0 9 8 3 4 e 3 6 9 8 8 a c , 7 6 a 9 1 4 6 8 6 8 c 4 6 e 6 a 8 e a 7 8 6 0 9 5 4 a 2 0 8 c 7 7 d 4 b b f 0 1 4 b a f 7 1 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
special数据: 6 0 8 8 1 2 , 5 7 0 0 , 1 , 6 1 4 5 1 2 , 2 , 3 8 2 9 4 1 , 2 2 5 8 7 1 , 1 , 1 , 1 , 1 H j J i e P 9 4 m y w u g 3 E 7 n C z B W F 3 q 3 1 L r S 3 e L R , 1 8 X m f 1 3 D 3 i s Q w A w z T m h S c T 1 N 1 Y 5 9 X p u k o 6 , 1 2 7 y n p m N 3 g E M z Z 6 m A p i v z y q n j q z t 1 q G E L x , f a 4 e 7 a 6 f 3 5 b 0 d d a 5 f 7 5 5 0 3 d a 2 0 f d 3 a 9 3 4 b 4 4 c 6 f a 3 f 3 a e a f 9 e 1 f 7 8 e e 9 c 1 3 3 d b 7 4 , 4 1 7 1 a 5 8 7 c b 8 b 4 2 7 3 4 a 3 1 b f c b 0 1 4 3 6 d c 1 2 4 c a 4 e e a 8 1 b 6 3 e b 2 0 3 9 a 3 d 5 1 2 a f f 1 5 7 4 , 4 7 3 0 4 4 0 2 2 0 0 c 3 5 c 5 1 6 b 3 f 3 2 b c 2 c 5 6 f 5 b f 8 f 1 f e 7 0 d a 1 c 4 f 9 6 e 3 d 3 f 5 1 2 d 9 f 4 2 c b f 5 7 1 5 1 5 4 2 3 0 0 2 2 0 6 7 4 d 3 1 6 b 7 7 d a 3 6 d 0 5 3 1 4 d 2 2 d e d f d 8 a 1 1 b 4 e c 7 d 1 d c 1 1 c a a a f b d 6 f e c 9 3 0 b 1 9 c 2 2 f 0 1 2 1 0 3 4 0 b c 6 1 d 0 a b 9 a 1 1 e 2 a 6 e f e 1 c 3 8 b 6 f d 0 6 d 9 9 0 5 9 7 b 5 b b 0 7 7 7 1 e 4 c 3 0 3 1 5 5 5 1 6 8 c 7 6 2 , 7 6 a 9 1 4 5 2 9 a a 2 b 7 5 a e f 0 7 1 4 f 5 7 3 8 0 1 5 a 6 8 a f a 4 0 f 6 4 9 f 7 a 1 8 8 a c , 7 6 a 9 1 4 0 c 4 a 0 7 0 a e 5 5 7 6 e 1 a 4 a b 7 c f d 3 8 6 c c 3 7 2 1 4 1 8 7 f 7 6 8 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
normal数据: ./dataset/1in2outPN.json
special数据: ./dataset/1_LSB.json
#word_index {'1': 1, '2': 2, '0': 3, '4': 4, 'a': 5, '8': 6, '7': 7, '3': 8, '6': 9, '9': 10, '5': 11, 'e': 12, 'c': 13, 'b': 14, 'd': 15, 'f': 16, 'o': 17, 'h': 18, 'y': 19, 'p': 20, 'N': 21, 'n': 22, 't': 23, 's': 24, 'k': 25, 'u': 26, 'A': 27, 'G': 28, 'E': 29, 'J': 30, 'B': 31, 'L': 32, 'P': 33, 'H': 34, 'F': 35, 'Q': 36, 'Z': 37, 'M': 38, 'T': 39, 'x': 40, 'K': 41, 'D': 42, 'W': 43, 'Y': 44, 'C': 45, 'g': 46, 'q': 47, 'i': 48, 'z': 49, 'U': 50, 'v': 51, 'r': 52, 'X': 53, 'w': 54, 'R': 55, 'S': 56, 'm': 57, 'j': 58, 'V': 59, 'l': 60}
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1400)]       0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1400, 300)    18300       input_1[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1400, 256)    230656      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 1400, 256)    307456      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 1400, 256)    384256      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 1400, 256)    1536256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 1400, 256)    2304256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 1400, 256)    3072256     embedding[0][0]                  
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 29, 256)      0           conv1d[0][0]                     
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 29, 256)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 29, 256)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 29, 256)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 29, 256)      0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 29, 256)      0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 29, 1536)     0           max_pooling1d[0][0]              
                                                                 max_pooling1d_1[0][0]            
                                                                 max_pooling1d_2[0][0]            
                                                                 max_pooling1d_3[0][0]            
                                                                 max_pooling1d_4[0][0]            
                                                                 max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 44544)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 44544)        0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            89090       dropout[0][0]                    
==================================================================================================
Total params: 7,942,526
Trainable params: 7,924,226
Non-trainable params: 18,300
__________________________________________________________________________________________________
Epoch 1/50
 1/11 [=>............................] - ETA: 1:06 - loss: 0.6962 - accuracy: 0.5067 - lr: 0.0050 2/11 [====>.........................] - ETA: 53s - loss: 6.7801 - accuracy: 0.4983 - lr: 0.0050  3/11 [=======>......................] - ETA: 47s - loss: 7.9236 - accuracy: 0.4930 - lr: 0.0050 4/11 [=========>....................] - ETA: 41s - loss: 7.8990 - accuracy: 0.5001 - lr: 0.0050 5/11 [============>.................] - ETA: 35s - loss: 7.6001 - accuracy: 0.5092 - lr: 0.0050 6/11 [===============>..............] - ETA: 29s - loss: 7.2511 - accuracy: 0.5145 - lr: 0.0050 7/11 [==================>...........] - ETA: 23s - loss: 6.9019 - accuracy: 0.5206 - lr: 0.0050 8/11 [====================>.........] - ETA: 17s - loss: 6.5772 - accuracy: 0.5258 - lr: 0.0050 9/11 [=======================>......] - ETA: 11s - loss: 6.2803 - accuracy: 0.5304 - lr: 0.005010/11 [==========================>...] - ETA: 5s - loss: 6.0098 - accuracy: 0.5351 - lr: 0.0050 11/11 [==============================] - ETA: 0s - loss: 5.7858 - accuracy: 0.5388 - lr: 0.005011/11 [==============================] - 63s 6s/step - loss: 5.5992 - accuracy: 0.5418 - lr: 0.0050 - val_loss: 0.5996 - val_accuracy: 0.6213 - val_lr: 0.0050

Epoch 00001: val_loss improved from inf to 0.59963, saving model to ./checkpoints/model.h5
Epoch 2/50
 1/11 [=>............................] - ETA: 1:00 - loss: 0.5695 - accuracy: 0.6533 - lr: 0.0050 2/11 [====>.........................] - ETA: 54s - loss: 0.5946 - accuracy: 0.6500 - lr: 0.0050  3/11 [=======>......................] - ETA: 47s - loss: 0.5901 - accuracy: 0.6556 - lr: 0.0050 4/11 [=========>....................] - ETA: 41s - loss: 0.5851 - accuracy: 0.6600 - lr: 0.0050 5/11 [============>.................] - ETA: 35s - loss: 0.5807 - accuracy: 0.6704 - lr: 0.0050 6/11 [===============>..............] - ETA: 29s - loss: 0.5752 - accuracy: 0.6824 - lr: 0.0050 7/11 [==================>...........] - ETA: 23s - loss: 0.5691 - accuracy: 0.6950 - lr: 0.0050 8/11 [====================>.........] - ETA: 17s - loss: 0.5624 - accuracy: 0.7053 - lr: 0.0050 9/11 [=======================>......] - ETA: 11s - loss: 0.5556 - accuracy: 0.7132 - lr: 0.005010/11 [==========================>...] - ETA: 5s - loss: 0.5486 - accuracy: 0.7207 - lr: 0.0050 11/11 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.7271 - lr: 0.005011/11 [==============================] - 62s 6s/step - loss: 0.5377 - accuracy: 0.7324 - lr: 0.0050 - val_loss: 0.2749 - val_accuracy: 0.9527 - val_lr: 0.0050

Epoch 00002: val_loss improved from 0.59963 to 0.27491, saving model to ./checkpoints/model.h5
Epoch 3/50
 1/11 [=>............................] - ETA: 58s - loss: 0.2552 - accuracy: 0.9533 - lr: 0.0050 2/11 [====>.........................] - ETA: 52s - loss: 0.2316 - accuracy: 0.9617 - lr: 0.0050 3/11 [=======>......................] - ETA: 47s - loss: 0.2267 - accuracy: 0.9589 - lr: 0.0050 4/11 [=========>....................] - ETA: 41s - loss: 0.2204 - accuracy: 0.9567 - lr: 0.0050 5/11 [============>.................] - ETA: 35s - loss: 0.2139 - accuracy: 0.9563 - lr: 0.0050 6/11 [===============>..............] - ETA: 29s - loss: 0.2077 - accuracy: 0.9567 - lr: 0.0050 7/11 [==================>...........] - ETA: 23s - loss: 0.2019 - accuracy: 0.9569 - lr: 0.0050 8/11 [====================>.........] - ETA: 17s - loss: 0.1968 - accuracy: 0.9571 - lr: 0.0050 9/11 [=======================>......] - ETA: 11s - loss: 0.1916 - accuracy: 0.9577 - lr: 0.005010/11 [==========================>...] - ETA: 5s - loss: 0.1871 - accuracy: 0.9582 - lr: 0.0050 11/11 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9585 - lr: 0.005011/11 [==============================] - 62s 6s/step - loss: 0.1804 - accuracy: 0.9589 - lr: 0.0050 - val_loss: 0.0629 - val_accuracy: 0.9763 - val_lr: 0.0050

Epoch 00003: val_loss improved from 0.27491 to 0.06289, saving model to ./checkpoints/model.h5
Epoch 4/50
 1/11 [=>............................] - ETA: 58s - loss: 0.0682 - accuracy: 0.9800 - lr: 0.0050 2/11 [====>.........................] - ETA: 53s - loss: 0.0758 - accuracy: 0.9750 - lr: 0.0050 3/11 [=======>......................] - ETA: 47s - loss: 0.0769 - accuracy: 0.9737 - lr: 0.0050 4/11 [=========>....................] - ETA: 41s - loss: 0.0765 - accuracy: 0.9740 - lr: 0.0050 5/11 [============>.................] - ETA: 35s - loss: 0.0761 - accuracy: 0.9744 - lr: 0.0050 6/11 [===============>..............] - ETA: 29s - loss: 0.0758 - accuracy: 0.9750 - lr: 0.0050 7/11 [==================>...........] - ETA: 23s - loss: 0.0747 - accuracy: 0.9756 - lr: 0.0050