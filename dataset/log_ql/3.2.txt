3.2 调整了 原始 的字段顺序 ，并删除了几个字段 0.778



2023-09-07 22:37:57.065188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
数据提取对象: all
#maxlength= 1069
#maxlength= 979
normal数据: 1 2 8 4 7 4 7 , 4 9 7 2 , 1 , 1 2 8 9 7 1 9 , 2 , 5 6 5 5 8 0 , 7 1 9 1 6 7 , 1 2 2 Z B j 5 S o G M r s Z e 3 v g A r v 7 i F K 2 q j K D Q Z P g , 1 C i N z v 1 v H k P r P f s c T 7 6 2 a s k P G Z Q T 5 L W i b g , 1 A X 4 n K 2 5 a b X 9 n D t Y M E V U A a 5 R i 8 5 Q A q Y E E p , 4 7 3 0 4 4 0 2 2 0 7 d 8 c e f b 2 6 9 8 8 3 c 3 a 1 2 c 1 6 3 a 3 9 1 e 9 b 7 6 2 b f 5 4 4 3 5 3 1 a 1 e 2 8 5 0 e e 6 d a b 3 d f 7 b f 9 1 a a 0 2 2 0 0 7 a c f a 0 5 2 e 7 f d 7 0 b f 3 7 7 b 1 3 d 5 a 1 c f 5 2 0 3 5 2 e 2 9 c e e f 9 8 d 6 d e c 2 a 6 1 8 4 c 3 9 b 3 1 b a a 0 1 2 1 0 3 f 5 6 b b f d 6 9 a a 0 e 1 2 6 4 6 8 c 0 d 9 5 c 2 7 4 9 8 f a 8 2 6 6 9 8 5 2 d 9 5 1 f e 5 b 6 5 d b 1 0 a b 6 e f e 4 5 2 3 , 7 6 a 9 1 4 8 0 7 c c d 2 e a 9 f 2 0 1 8 2 2 c 5 c 6 e 0 d 4 0 8 c b 9 a 0 9 8 3 4 e 3 6 9 8 8 a c , 7 6 a 9 1 4 6 8 6 8 c 4 6 e 6 a 8 e a 7 8 6 0 9 5 4 a 2 0 8 c 7 7 d 4 b b f 0 1 4 b a f 7 1 8 8 a c
special数据: 8 6 4 4 1 8 7 1 , 1 5 4 8 6 , 1 , 8 6 4 5 7 3 5 7 , 2 , 1 6 1 0 0 0 0 0 , 7 0 3 4 1 8 7 1 , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 B 5 Z T 4 D k k n J C 7 e 9 X Z w G Y S Y Y V t y J o d X V x c S , 4 7 3 0 4 4 0 2 2 0 6 6 4 1 5 5 0 f 5 e 3 5 0 6 f a 9 c e 5 d 3 c 0 d 8 a 5 6 8 f 3 0 6 d 6 a 7 a 1 f 2 b 6 7 2 3 e 9 e 4 e c a d 4 0 b d 7 6 d 0 6 0 2 2 0 6 6 c f 6 8 c 4 7 e e 1 6 0 4 b 5 e c 7 2 c 1 a 4 4 2 4 d 7 9 4 0 e e f a a 1 b 5 e 2 a 9 b 3 9 6 c 1 2 c 7 1 a 8 2 8 5 4 5 b 5 0 1 2 1 0 2 d e a b 7 6 c a 9 8 8 4 0 8 c 2 6 e 5 b c 8 2 7 5 d 1 0 0 5 6 1 3 2 2 e b 2 5 e 7 4 3 4 f d b 8 4 b e 9 5 e c c 8 9 5 8 4 3 1 9 , 7 6 a 9 1 4 2 6 f 5 5 d a e e b 9 5 5 7 d 7 a 4 1 e 7 c 7 5 6 d 3 8 3 3 7 9 3 e a 7 0 3 5 4 8 8 a c , 7 6 a 9 1 4 6 e 8 e 0 2 4 9 e d b 3 9 0 3 6 1 3 6 a 4 c 7 3 2 5 f 0 0 0 4 0 0 1 3 7 f 2 a 1 8 8 a c
normal数据: ./dataset/1in2outPN.json
special数据: ./dataset/7_CHT02.json
#word_index {'1': 1, '0': 2, '2': 3, '4': 4, '8': 5, '7': 6, '3': 7, '6': 8, '9': 9, 'a': 10, '5': 11, 'c': 12, 'd': 13, 'b': 14, 'e': 15, 'f': 16, 'A': 17, 'N': 18, 'E': 19, 'B': 20, 'P': 21, 'J': 22, 'T': 23, 'D': 24, 'H': 25, 'L': 26, 'F': 27, 'M': 28, 'o': 29, 'G': 30, 'k': 31, 'Z': 32, 'C': 33, 'Q': 34, 'w': 35, 'n': 36, 'Y': 37, 'W': 38, 'K': 39, 'g': 40, 'x': 41, 'v': 42, 'y': 43, 'U': 44, 'S': 45, 'r': 46, 'z': 47, 'p': 48, 'i': 49, 'q': 50, 't': 51, 's': 52, 'h': 53, 'm': 54, 'V': 55, 'u': 56, 'X': 57, 'R': 58, 'j': 59}
alldata[1] [7 2 8 ... 0 0 0]
all_label_oh[1008] [1. 0.] 2087
train_data_num: 1669
train_label_num: 1669
val_data_num: 418
val_label_num: 418
2023-09-07 22:37:58.805181: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-07 22:37:58.805927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-09-07 22:37:58.866465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:37:58.866625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:37:58.866652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:37:58.868938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:37:58.869073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:37:58.869807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-07 22:37:58.870059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-07 22:37:58.871381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-07 22:37:58.871989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-07 22:37:58.872120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:37:58.872606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-07 22:37:58.872918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-07 22:37:58.874138: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-07 22:37:59.002249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:37:59.002593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:37:59.002633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:37:59.002668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:37:59.002679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:37:59.002689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-07 22:37:59.002698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-07 22:37:59.002708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-07 22:37:59.002718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-07 22:37:59.002728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:37:59.003080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-07 22:37:59.003104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:37:59.661439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-09-07 22:37:59.661474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2023-09-07 22:37:59.661479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N 
2023-09-07 22:37:59.661482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N 
2023-09-07 22:37:59.662139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22411 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6)
2023-09-07 22:37:59.662839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22215 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)
初始lr= 0.005
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1400)]       0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1400, 300)    18300       input_1[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1400, 256)    230656      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 1400, 256)    307456      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 1400, 256)    384256      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 1400, 256)    1536256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 1400, 256)    2304256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 1400, 256)    3072256     embedding[0][0]                  
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 29, 256)      0           conv1d[0][0]                     
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 29, 256)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 29, 256)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 29, 256)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 29, 256)      0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 29, 256)      0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 29, 1536)     0           max_pooling1d[0][0]              
                                                                 max_pooling1d_1[0][0]            
                                                                 max_pooling1d_2[0][0]            
                                                                 max_pooling1d_3[0][0]            
                                                                 max_pooling1d_4[0][0]            
                                                                 max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 44544)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 44544)        0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            89090       dropout[0][0]                    
==================================================================================================
Total params: 7,942,526
Trainable params: 7,924,226
Non-trainable params: 18,300
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2023-09-07 22:37:59.963726: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-09-07 22:37:59.984002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3499910000 Hz
Epoch 1/50
2023-09-07 22:38:00.633034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:38:01.234836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:38:01.264345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:38:05.026543: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
8/8 [==============================] - 12s 693ms/step - loss: 5.0115 - accuracy: 0.4775 - lr: 0.0050 - val_loss: 0.6722 - val_accuracy: 0.5210 - val_lr: 0.0050

Epoch 00001: val_loss improved from inf to 0.67217, saving model to ./checkpoints/model.h5
Epoch 2/50
8/8 [==============================] - 2s 284ms/step - loss: 0.6345 - accuracy: 0.6213 - lr: 0.0050 - val_loss: 0.6183 - val_accuracy: 0.6347 - val_lr: 0.0050

Epoch 00002: val_loss improved from 0.67217 to 0.61828, saving model to ./checkpoints/model.h5
Epoch 3/50
8/8 [==============================] - 2s 284ms/step - loss: 0.5094 - accuracy: 0.8192 - lr: 0.0050 - val_loss: 0.6109 - val_accuracy: 0.6168 - val_lr: 0.0050

Epoch 00003: val_loss improved from 0.61828 to 0.61094, saving model to ./checkpoints/model.h5
Epoch 4/50
8/8 [==============================] - 2s 285ms/step - loss: 0.3402 - accuracy: 0.9007 - lr: 0.0050 - val_loss: 0.6662 - val_accuracy: 0.6347 - val_lr: 0.0050

Epoch 00004: val_loss did not improve from 0.61094
Epoch 5/50
8/8 [==============================] - 2s 285ms/step - loss: 0.1833 - accuracy: 0.9676 - lr: 0.0050 - val_loss: 0.5451 - val_accuracy: 0.6707 - val_lr: 0.0050

Epoch 00005: val_loss improved from 0.61094 to 0.54509, saving model to ./checkpoints/model.h5
Epoch 6/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0591 - accuracy: 0.9997 - lr: 0.0050 - val_loss: 0.5603 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00006: val_loss did not improve from 0.54509
Epoch 7/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0217 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5316 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00007: val_loss improved from 0.54509 to 0.53160, saving model to ./checkpoints/model.h5
Epoch 8/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0102 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5391 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00008: val_loss did not improve from 0.53160
Epoch 9/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0074 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5558 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00009: val_loss did not improve from 0.53160
Epoch 10/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0051 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5918 - val_accuracy: 0.7066 - val_lr: 0.0050

Epoch 00010: val_loss did not improve from 0.53160
Epoch 11/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0037 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5707 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00011: val_loss did not improve from 0.53160
Epoch 12/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0026 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5516 - val_accuracy: 0.7246 - val_lr: 0.0050

Epoch 00012: val_loss did not improve from 0.53160
Epoch 13/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5847 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00013: val_loss did not improve from 0.53160
Epoch 14/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0019 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5572 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00014: val_loss did not improve from 0.53160
Epoch 15/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5789 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00015: val_loss did not improve from 0.53160
Epoch 16/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5837 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00016: val_loss did not improve from 0.53160
Epoch 17/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5841 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00017: val_loss did not improve from 0.53160
Epoch 18/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5839 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00018: val_loss did not improve from 0.53160
Epoch 19/50
8/8 [==============================] - 2s 285ms/step - loss: 9.1509e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5939 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00019: val_loss did not improve from 0.53160
Epoch 20/50
8/8 [==============================] - 2s 285ms/step - loss: 9.8835e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5763 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00020: val_loss did not improve from 0.53160
Epoch 21/50
8/8 [==============================] - 2s 285ms/step - loss: 8.4899e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5899 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00021: val_loss did not improve from 0.53160
Epoch 22/50
8/8 [==============================] - 2s 286ms/step - loss: 7.2441e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5928 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00022: val_loss did not improve from 0.53160
Epoch 23/50
8/8 [==============================] - 2s 285ms/step - loss: 6.8617e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5900 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00023: val_loss did not improve from 0.53160
Epoch 24/50
8/8 [==============================] - 2s 286ms/step - loss: 6.9943e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5920 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00024: val_loss did not improve from 0.53160
Epoch 25/50
8/8 [==============================] - 2s 286ms/step - loss: 6.6060e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5883 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00025: val_loss did not improve from 0.53160
Epoch 26/50
8/8 [==============================] - 2s 286ms/step - loss: 6.2126e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5941 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00026: val_loss did not improve from 0.53160
Epoch 27/50
8/8 [==============================] - 2s 286ms/step - loss: 5.1001e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6093 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00027: val_loss did not improve from 0.53160
Epoch 28/50
8/8 [==============================] - 2s 286ms/step - loss: 5.2164e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5999 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00028: val_loss did not improve from 0.53160
Epoch 29/50
8/8 [==============================] - 2s 286ms/step - loss: 4.3994e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5937 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00029: val_loss did not improve from 0.53160
Epoch 30/50
8/8 [==============================] - 2s 286ms/step - loss: 4.4095e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6175 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00030: val_loss did not improve from 0.53160
Epoch 31/50
8/8 [==============================] - 2s 286ms/step - loss: 4.0883e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6040 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00031: val_loss did not improve from 0.53160
Epoch 32/50
8/8 [==============================] - 2s 286ms/step - loss: 4.0067e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6015 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00032: val_loss did not improve from 0.53160
Epoch 33/50
8/8 [==============================] - 2s 286ms/step - loss: 3.7275e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.5992 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00033: val_loss did not improve from 0.53160
Epoch 34/50
8/8 [==============================] - 2s 285ms/step - loss: 3.7769e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6202 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00034: val_loss did not improve from 0.53160
Epoch 35/50
8/8 [==============================] - 2s 286ms/step - loss: 3.3220e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6235 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00035: val_loss did not improve from 0.53160
Epoch 36/50
8/8 [==============================] - 2s 286ms/step - loss: 3.3517e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6066 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00036: val_loss did not improve from 0.53160
Epoch 37/50
8/8 [==============================] - 2s 287ms/step - loss: 3.0518e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6152 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00037: val_loss did not improve from 0.53160
Epoch 38/50
8/8 [==============================] - 2s 286ms/step - loss: 3.0525e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6139 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00038: val_loss did not improve from 0.53160
Epoch 39/50
8/8 [==============================] - 2s 286ms/step - loss: 3.1661e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6115 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00039: val_loss did not improve from 0.53160
Epoch 40/50
8/8 [==============================] - 2s 287ms/step - loss: 2.7103e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6148 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00040: val_loss did not improve from 0.53160
Epoch 41/50
8/8 [==============================] - 2s 287ms/step - loss: 2.9430e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6236 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00041: val_loss did not improve from 0.53160
Epoch 42/50
8/8 [==============================] - 2s 286ms/step - loss: 2.4261e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6269 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00042: val_loss did not improve from 0.53160
Epoch 43/50
8/8 [==============================] - 2s 286ms/step - loss: 2.2428e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6254 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00043: val_loss did not improve from 0.53160
Epoch 44/50
8/8 [==============================] - 2s 287ms/step - loss: 2.4385e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6142 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00044: val_loss did not improve from 0.53160
Epoch 45/50
8/8 [==============================] - 2s 287ms/step - loss: 2.2220e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6125 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00045: val_loss did not improve from 0.53160
Epoch 46/50
8/8 [==============================] - 2s 287ms/step - loss: 2.2100e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6208 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00046: val_loss did not improve from 0.53160
Epoch 47/50
8/8 [==============================] - 2s 286ms/step - loss: 1.8437e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6233 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00047: val_loss did not improve from 0.53160
Epoch 48/50
8/8 [==============================] - 2s 287ms/step - loss: 1.8330e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6294 - val_accuracy: 0.7246 - val_lr: 0.0050

Epoch 00048: val_loss did not improve from 0.53160
Epoch 49/50
8/8 [==============================] - 2s 287ms/step - loss: 2.0802e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6153 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00049: val_loss did not improve from 0.53160
Epoch 50/50
8/8 [==============================] - 2s 287ms/step - loss: 1.7205e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.6259 - val_accuracy: 0.7186 - val_lr: 0.0050

Epoch 00050: val_loss did not improve from 0.53160
14/14 [==============================] - 1s 28ms/step
准确率 精度 召回率 平均f1-score
0.777511961722488
0.7865839589991868
0.777511961722488
0.7750446495172204


CNN 1D - Train accuracy: 0.971

CNN 1D of Training data
               precision    recall  f1-score   support

           0       0.98      0.96      0.97       802
           1       0.96      0.99      0.97       867

    accuracy                           0.97      1669
   macro avg       0.97      0.97      0.97      1669
weighted avg       0.97      0.97      0.97      1669


CNN 1D - Train Confusion Matrix

 Predicted    0    1
Actuall            
0          767   35
1           13  854

CNN 1D - Test accuracy: 0.778

CNN 1D of Test data
               precision    recall  f1-score   support

           0       0.84      0.68      0.75       204
           1       0.74      0.87      0.80       214

    accuracy                           0.78       418
   macro avg       0.79      0.78      0.77       418
weighted avg       0.79      0.78      0.78       418


CNN 1D - Test Confusion Matrix

 Predicted    0    1
Actuall            
0          138   66
1           27  187
normalpath: ./dataset/1in2outPN.json
specialpath: ./dataset/7_CHT02.json
耗时:129.1880488395691