2.5 调整了 原始 的字段顺序 0.847



2023-09-07 22:05:47.109809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
数据提取对象: all
#maxlength= 1635
#maxlength= 1335
normal数据: 1 2 8 4 7 4 7 , 4 9 7 2 , 1 , 1 2 8 9 7 1 9 , 2 , 5 6 5 5 8 0 , 7 1 9 1 6 7 , 1 2 2 Z B j 5 S o G M r s Z e 3 v g A r v 7 i F K 2 q j K D Q Z P g , 1 C i N z v 1 v H k P r P f s c T 7 6 2 a s k P G Z Q T 5 L W i b g , 1 A X 4 n K 2 5 a b X 9 n D t Y M E V U A a 5 R i 8 5 Q A q Y E E p , 6 f 7 7 f 1 4 1 e e a 9 9 0 3 c f d e a 1 1 4 8 e 2 b c 3 7 d 5 0 0 5 6 9 6 5 0 9 9 a 6 8 7 9 d 1 5 8 f 5 6 2 b 4 b 9 b f e 2 a , 9 5 d e 1 7 b 2 3 6 8 f 5 3 2 a b b 9 0 2 f 8 4 c 8 e 3 8 5 a 4 2 4 9 f c 2 c 2 3 1 b 5 9 8 2 f b f b 4 1 8 c 2 1 9 a b c d 0 9 , 4 7 3 0 4 4 0 2 2 0 7 d 8 c e f b 2 6 9 8 8 3 c 3 a 1 2 c 1 6 3 a 3 9 1 e 9 b 7 6 2 b f 5 4 4 3 5 3 1 a 1 e 2 8 5 0 e e 6 d a b 3 d f 7 b f 9 1 a a 0 2 2 0 0 7 a c f a 0 5 2 e 7 f d 7 0 b f 3 7 7 b 1 3 d 5 a 1 c f 5 2 0 3 5 2 e 2 9 c e e f 9 8 d 6 d e c 2 a 6 1 8 4 c 3 9 b 3 1 b a a 0 1 2 1 0 3 f 5 6 b b f d 6 9 a a 0 e 1 2 6 4 6 8 c 0 d 9 5 c 2 7 4 9 8 f a 8 2 6 6 9 8 5 2 d 9 5 1 f e 5 b 6 5 d b 1 0 a b 6 e f e 4 5 2 3 , 7 6 a 9 1 4 8 0 7 c c d 2 e a 9 f 2 0 1 8 2 2 c 5 c 6 e 0 d 4 0 8 c b 9 a 0 9 8 3 4 e 3 6 9 8 8 a c , 7 6 a 9 1 4 6 8 6 8 c 4 6 e 6 a 8 e a 7 8 6 0 9 5 4 a 2 0 8 c 7 7 d 4 b b f 0 1 4 b a f 7 1 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
special数据: 8 6 4 4 1 8 7 1 , 1 5 4 8 6 , 1 , 8 6 4 5 7 3 5 7 , 2 , 1 6 1 0 0 0 0 0 , 7 0 3 4 1 8 7 1 , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 B 5 Z T 4 D k k n J C 7 e 9 X Z w G Y S Y Y V t y J o d X V x c S , 1 c e b 8 4 3 5 3 a 4 8 0 7 2 8 3 b 0 7 1 9 d 0 7 3 d e f 7 e e a 7 b c 1 a 4 f 4 c 7 5 f c 6 1 9 0 5 0 a d e e 7 0 7 0 1 1 8 1 , 8 c 6 9 5 8 f d 5 7 5 d 3 2 8 9 9 d b 3 e 3 6 2 1 4 e 2 4 d 7 b c c c d c 7 9 2 2 6 5 c f 6 b 7 2 f 9 0 b a 2 b 9 3 d 1 e 7 1 9 , 4 7 3 0 4 4 0 2 2 0 6 6 4 1 5 5 0 f 5 e 3 5 0 6 f a 9 c e 5 d 3 c 0 d 8 a 5 6 8 f 3 0 6 d 6 a 7 a 1 f 2 b 6 7 2 3 e 9 e 4 e c a d 4 0 b d 7 6 d 0 6 0 2 2 0 6 6 c f 6 8 c 4 7 e e 1 6 0 4 b 5 e c 7 2 c 1 a 4 4 2 4 d 7 9 4 0 e e f a a 1 b 5 e 2 a 9 b 3 9 6 c 1 2 c 7 1 a 8 2 8 5 4 5 b 5 0 1 2 1 0 2 d e a b 7 6 c a 9 8 8 4 0 8 c 2 6 e 5 b c 8 2 7 5 d 1 0 0 5 6 1 3 2 2 e b 2 5 e 7 4 3 4 f d b 8 4 b e 9 5 e c c 8 9 5 8 4 3 1 9 , 7 6 a 9 1 4 2 6 f 5 5 d a e e b 9 5 5 7 d 7 a 4 1 e 7 c 7 5 6 d 3 8 3 3 7 9 3 e a 7 0 3 5 4 8 8 a c , 7 6 a 9 1 4 6 e 8 e 0 2 4 9 e d b 3 9 0 3 6 1 3 6 a 4 c 7 3 2 5 f 0 0 0 4 0 0 1 3 7 f 2 a 1 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
normal数据: ./dataset/1in2outPN.json
special数据: ./dataset/7_CHT02.json
#word_index {'1': 1, '0': 2, '2': 3, '4': 4, 'a': 5, '8': 6, '7': 7, '3': 8, '6': 9, '9': 10, 'e': 11, '5': 12, 'c': 13, 'b': 14, 'd': 15, 'f': 16, 'o': 17, 'y': 18, 'p': 19, 'h': 20, 'N': 21, 'n': 22, 'k': 23, 't': 24, 'u': 25, 's': 26, 'A': 27, 'E': 28, 'B': 29, 'P': 30, 'J': 31, 'T': 32, 'D': 33, 'H': 34, 'L': 35, 'F': 36, 'M': 37, 'G': 38, 'Z': 39, 'C': 40, 'Q': 41, 'w': 42, 'Y': 43, 'W': 44, 'K': 45, 'g': 46, 'x': 47, 'v': 48, 'U': 49, 'S': 50, 'r': 51, 'z': 52, 'i': 53, 'q': 54, 'm': 55, 'V': 56, 'X': 57, 'R': 58, 'j': 59, 'l': 60}
alldata[1] [8 8 8 ... 0 0 0]
all_label_oh[1008] [0. 1.] 2087
train_data_num: 1669
train_label_num: 1669
val_data_num: 418
val_label_num: 418
2023-09-07 22:05:49.036568: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-07 22:05:49.037327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-09-07 22:05:49.098496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:05:49.098673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:05:49.098703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:05:49.101034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:05:49.101171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:05:49.101910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-07 22:05:49.102160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-07 22:05:49.103503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-07 22:05:49.104100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-07 22:05:49.104236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:05:49.104737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-07 22:05:49.105049: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-07 22:05:49.106189: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-07 22:05:49.223737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:05:49.223905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-07 22:05:49.223940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:05:49.223967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:05:49.223975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:05:49.223983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-07 22:05:49.223991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-07 22:05:49.224000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-07 22:05:49.224008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-07 22:05:49.224017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:05:49.224462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-07 22:05:49.224492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-07 22:05:49.878377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-09-07 22:05:49.878422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2023-09-07 22:05:49.878428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N 
2023-09-07 22:05:49.878430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N 
2023-09-07 22:05:49.879131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22411 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6)
2023-09-07 22:05:49.879821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22217 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)
初始lr= 0.005
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1400)]       0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1400, 300)    18300       input_1[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1400, 256)    230656      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 1400, 256)    307456      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 1400, 256)    384256      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 1400, 256)    1536256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 1400, 256)    2304256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 1400, 256)    3072256     embedding[0][0]                  
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 29, 256)      0           conv1d[0][0]                     
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 29, 256)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 29, 256)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 29, 256)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 29, 256)      0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 29, 256)      0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 29, 1536)     0           max_pooling1d[0][0]              
                                                                 max_pooling1d_1[0][0]            
                                                                 max_pooling1d_2[0][0]            
                                                                 max_pooling1d_3[0][0]            
                                                                 max_pooling1d_4[0][0]            
                                                                 max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 44544)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 44544)        0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            89090       dropout[0][0]                    
==================================================================================================
Total params: 7,942,526
Trainable params: 7,924,226
Non-trainable params: 18,300
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2023-09-07 22:05:50.176607: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-09-07 22:05:50.196001: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3499910000 Hz
Epoch 1/50
2023-09-07 22:05:50.854619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-07 22:05:51.445540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-07 22:05:51.475081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-07 22:05:55.249510: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
8/8 [==============================] - 12s 693ms/step - loss: 3.8780 - accuracy: 0.5126 - lr: 0.0050 - val_loss: 0.9228 - val_accuracy: 0.4731 - val_lr: 0.0050

Epoch 00001: val_loss improved from inf to 0.92278, saving model to ./checkpoints/model.h5
Epoch 2/50
8/8 [==============================] - 2s 284ms/step - loss: 0.9961 - accuracy: 0.5146 - lr: 0.0050 - val_loss: 0.6493 - val_accuracy: 0.6048 - val_lr: 0.0050

Epoch 00002: val_loss improved from 0.92278 to 0.64925, saving model to ./checkpoints/model.h5
Epoch 3/50
8/8 [==============================] - 2s 285ms/step - loss: 0.5909 - accuracy: 0.6693 - lr: 0.0050 - val_loss: 0.5379 - val_accuracy: 0.7126 - val_lr: 0.0050

Epoch 00003: val_loss improved from 0.64925 to 0.53791, saving model to ./checkpoints/model.h5
Epoch 4/50
8/8 [==============================] - 2s 285ms/step - loss: 0.4442 - accuracy: 0.8439 - lr: 0.0050 - val_loss: 0.5389 - val_accuracy: 0.7006 - val_lr: 0.0050

Epoch 00004: val_loss did not improve from 0.53791
Epoch 5/50
8/8 [==============================] - 2s 285ms/step - loss: 0.2798 - accuracy: 0.9337 - lr: 0.0050 - val_loss: 0.4617 - val_accuracy: 0.7844 - val_lr: 0.0050

Epoch 00005: val_loss improved from 0.53791 to 0.46173, saving model to ./checkpoints/model.h5
Epoch 6/50
8/8 [==============================] - 2s 285ms/step - loss: 0.1205 - accuracy: 0.9942 - lr: 0.0050 - val_loss: 0.4006 - val_accuracy: 0.8024 - val_lr: 0.0050

Epoch 00006: val_loss improved from 0.46173 to 0.40063, saving model to ./checkpoints/model.h5
Epoch 7/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0414 - accuracy: 0.9990 - lr: 0.0050 - val_loss: 0.3660 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00007: val_loss improved from 0.40063 to 0.36595, saving model to ./checkpoints/model.h5
Epoch 8/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0177 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3553 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00008: val_loss improved from 0.36595 to 0.35529, saving model to ./checkpoints/model.h5
Epoch 9/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0101 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3515 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00009: val_loss improved from 0.35529 to 0.35152, saving model to ./checkpoints/model.h5
Epoch 10/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0056 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3520 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00010: val_loss did not improve from 0.35152
Epoch 11/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0043 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3542 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00011: val_loss did not improve from 0.35152
Epoch 12/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0035 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3474 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00012: val_loss improved from 0.35152 to 0.34744, saving model to ./checkpoints/model.h5
Epoch 13/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0028 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3482 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00013: val_loss did not improve from 0.34744
Epoch 14/50
8/8 [==============================] - 2s 285ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3472 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00014: val_loss improved from 0.34744 to 0.34718, saving model to ./checkpoints/model.h5
Epoch 15/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0022 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3476 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00015: val_loss did not improve from 0.34718
Epoch 16/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3428 - val_accuracy: 0.8443 - val_lr: 0.0050

Epoch 00016: val_loss improved from 0.34718 to 0.34279, saving model to ./checkpoints/model.h5
Epoch 17/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0016 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3496 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00017: val_loss did not improve from 0.34279
Epoch 18/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3434 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00018: val_loss did not improve from 0.34279
Epoch 19/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3488 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00019: val_loss did not improve from 0.34279
Epoch 20/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3426 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00020: val_loss improved from 0.34279 to 0.34260, saving model to ./checkpoints/model.h5
Epoch 21/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3456 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00021: val_loss did not improve from 0.34260
Epoch 22/50
8/8 [==============================] - 2s 286ms/step - loss: 8.9327e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3460 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00022: val_loss did not improve from 0.34260
Epoch 23/50
8/8 [==============================] - 2s 286ms/step - loss: 9.6004e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3479 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00023: val_loss did not improve from 0.34260
Epoch 24/50
8/8 [==============================] - 2s 286ms/step - loss: 7.8467e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3438 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00024: val_loss did not improve from 0.34260
Epoch 25/50
8/8 [==============================] - 2s 287ms/step - loss: 7.6494e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3464 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00025: val_loss did not improve from 0.34260
Epoch 26/50
8/8 [==============================] - 2s 287ms/step - loss: 6.7168e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3479 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00026: val_loss did not improve from 0.34260
Epoch 27/50
8/8 [==============================] - 2s 287ms/step - loss: 7.1115e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3438 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00027: val_loss did not improve from 0.34260
Epoch 28/50
8/8 [==============================] - 2s 286ms/step - loss: 5.5451e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3451 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00028: val_loss did not improve from 0.34260
Epoch 29/50
8/8 [==============================] - 2s 287ms/step - loss: 5.2261e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3423 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00029: val_loss improved from 0.34260 to 0.34225, saving model to ./checkpoints/model.h5
Epoch 30/50
8/8 [==============================] - 2s 287ms/step - loss: 6.0293e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3529 - val_accuracy: 0.8443 - val_lr: 0.0050

Epoch 00030: val_loss did not improve from 0.34225
Epoch 31/50
8/8 [==============================] - 2s 287ms/step - loss: 5.0675e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3418 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00031: val_loss improved from 0.34225 to 0.34183, saving model to ./checkpoints/model.h5
Epoch 32/50
8/8 [==============================] - 2s 287ms/step - loss: 4.9099e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3509 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00032: val_loss did not improve from 0.34183
Epoch 33/50
8/8 [==============================] - 2s 287ms/step - loss: 4.2774e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3450 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00033: val_loss did not improve from 0.34183
Epoch 34/50
8/8 [==============================] - 2s 287ms/step - loss: 4.4115e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3435 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00034: val_loss did not improve from 0.34183
Epoch 35/50
8/8 [==============================] - 2s 287ms/step - loss: 4.1434e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3490 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00035: val_loss did not improve from 0.34183
Epoch 36/50
8/8 [==============================] - 2s 287ms/step - loss: 4.0641e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3426 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00036: val_loss did not improve from 0.34183
Epoch 37/50
8/8 [==============================] - 2s 287ms/step - loss: 3.7393e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3503 - val_accuracy: 0.8383 - val_lr: 0.0050

Epoch 00037: val_loss did not improve from 0.34183
Epoch 38/50
8/8 [==============================] - 2s 287ms/step - loss: 3.4567e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3477 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00038: val_loss did not improve from 0.34183
Epoch 39/50
8/8 [==============================] - 2s 287ms/step - loss: 3.4439e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3435 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00039: val_loss did not improve from 0.34183
Epoch 40/50
8/8 [==============================] - 2s 287ms/step - loss: 3.2624e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3440 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00040: val_loss did not improve from 0.34183
Epoch 41/50
8/8 [==============================] - 2s 287ms/step - loss: 3.0019e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3450 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00041: val_loss did not improve from 0.34183
Epoch 42/50
8/8 [==============================] - 2s 287ms/step - loss: 2.7009e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3504 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00042: val_loss did not improve from 0.34183
Epoch 43/50
8/8 [==============================] - 2s 287ms/step - loss: 2.6898e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3479 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00043: val_loss did not improve from 0.34183
Epoch 44/50
8/8 [==============================] - 2s 287ms/step - loss: 2.5959e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3466 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00044: val_loss did not improve from 0.34183
Epoch 45/50
8/8 [==============================] - 2s 287ms/step - loss: 2.6578e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3455 - val_accuracy: 0.8263 - val_lr: 0.0050

Epoch 00045: val_loss did not improve from 0.34183
Epoch 46/50
8/8 [==============================] - 2s 287ms/step - loss: 2.3784e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3469 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00046: val_loss did not improve from 0.34183
Epoch 47/50
8/8 [==============================] - 2s 287ms/step - loss: 2.8034e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3457 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00047: val_loss did not improve from 0.34183
Epoch 48/50
8/8 [==============================] - 2s 287ms/step - loss: 2.3699e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3482 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00048: val_loss did not improve from 0.34183
Epoch 49/50
8/8 [==============================] - 2s 287ms/step - loss: 2.2722e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3423 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00049: val_loss did not improve from 0.34183
Epoch 50/50
8/8 [==============================] - 2s 287ms/step - loss: 2.2947e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.3476 - val_accuracy: 0.8323 - val_lr: 0.0050

Epoch 00050: val_loss did not improve from 0.34183
14/14 [==============================] - 1s 28ms/step
准确率 精度 召回率 平均f1-score
0.84688995215311
0.8491137419531366
0.84688995215311
0.846414301921627


CNN 1D - Train accuracy: 0.983

CNN 1D of Training data
               precision    recall  f1-score   support

           0       0.99      0.98      0.98       803
           1       0.98      0.99      0.98       866

    accuracy                           0.98      1669
   macro avg       0.98      0.98      0.98      1669
weighted avg       0.98      0.98      0.98      1669


CNN 1D - Train Confusion Matrix

 Predicted    0    1
Actuall            
0          786   17
1           11  855

CNN 1D - Test accuracy: 0.847

CNN 1D of Test data
               precision    recall  f1-score   support

           0       0.88      0.80      0.84       203
           1       0.82      0.89      0.86       215

    accuracy                           0.85       418
   macro avg       0.85      0.85      0.85       418
weighted avg       0.85      0.85      0.85       418


CNN 1D - Test Confusion Matrix

 Predicted    0    1
Actuall            
0          162   41
1           23  192
normalpath: ./dataset/1in2outPN.json
specialpath: ./dataset/7_CHT02.json
耗时:130.97237825393677