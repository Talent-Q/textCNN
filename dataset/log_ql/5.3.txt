5.3 调整了 原始 的字段顺序，并加入 addr_txs_num 0.911



2023-09-08 13:17:03.930841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-08 13:17:04.962433: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-08 13:17:04.963546: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-08 13:17:04.964252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-09-08 13:17:05.084019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:05.084193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:05.084223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-08 13:17:05.086429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-08 13:17:05.086518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-08 13:17:05.087196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-08 13:17:05.087417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-08 13:17:05.088696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-08 13:17:05.089208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-08 13:17:05.089323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-08 13:17:05.089782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-08 13:17:05.089812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-08 13:17:05.783161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-09-08 13:17:05.783202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2023-09-08 13:17:05.783209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N 
2023-09-08 13:17:05.783214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N 
2023-09-08 13:17:05.783882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16044 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6)
2023-09-08 13:17:05.784499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 21837 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)
数据提取对象: all
#maxlength= 1651
#maxlength= 1347
normal数据: 1 2 8 4 7 4 7 , 4 9 7 2 , 1 , 1 2 8 9 7 1 9 , 2 , 5 6 5 5 8 0 , 7 1 9 1 6 7 , 2 7 3 , 2 3 8 , 2 , 1 2 2 Z B j 5 S o G M r s Z e 3 v g A r v 7 i F K 2 q j K D Q Z P g , 1 C i N z v 1 v H k P r P f s c T 7 6 2 a s k P G Z Q T 5 L W i b g , 1 A X 4 n K 2 5 a b X 9 n D t Y M E V U A a 5 R i 8 5 Q A q Y E E p , 6 f 7 7 f 1 4 1 e e a 9 9 0 3 c f d e a 1 1 4 8 e 2 b c 3 7 d 5 0 0 5 6 9 6 5 0 9 9 a 6 8 7 9 d 1 5 8 f 5 6 2 b 4 b 9 b f e 2 a , 9 5 d e 1 7 b 2 3 6 8 f 5 3 2 a b b 9 0 2 f 8 4 c 8 e 3 8 5 a 4 2 4 9 f c 2 c 2 3 1 b 5 9 8 2 f b f b 4 1 8 c 2 1 9 a b c d 0 9 , 4 7 3 0 4 4 0 2 2 0 7 d 8 c e f b 2 6 9 8 8 3 c 3 a 1 2 c 1 6 3 a 3 9 1 e 9 b 7 6 2 b f 5 4 4 3 5 3 1 a 1 e 2 8 5 0 e e 6 d a b 3 d f 7 b f 9 1 a a 0 2 2 0 0 7 a c f a 0 5 2 e 7 f d 7 0 b f 3 7 7 b 1 3 d 5 a 1 c f 5 2 0 3 5 2 e 2 9 c e e f 9 8 d 6 d e c 2 a 6 1 8 4 c 3 9 b 3 1 b a a 0 1 2 1 0 3 f 5 6 b b f d 6 9 a a 0 e 1 2 6 4 6 8 c 0 d 9 5 c 2 7 4 9 8 f a 8 2 6 6 9 8 5 2 d 9 5 1 f e 5 b 6 5 d b 1 0 a b 6 e f e 4 5 2 3 , 7 6 a 9 1 4 8 0 7 c c d 2 e a 9 f 2 0 1 8 2 2 c 5 c 6 e 0 d 4 0 8 c b 9 a 0 9 8 3 4 e 3 6 9 8 8 a c , 7 6 a 9 1 4 6 8 6 8 c 4 6 e 6 a 8 e a 7 8 6 0 9 5 4 a 2 0 8 c 7 7 d 4 b b f 0 1 4 b a f 7 1 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
special数据: 8 6 4 4 1 8 7 1 , 1 5 4 8 6 , 1 , 8 6 4 5 7 3 5 7 , 2 , 1 6 1 0 0 0 0 0 , 7 0 3 4 1 8 7 1 , 2 , 2 , 2 , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 4 Y z c c e i q 8 v i S v J S v C w 4 H y 2 Q P B D R u f j j Y r , 1 B 5 Z T 4 D k k n J C 7 e 9 X Z w G Y S Y Y V t y J o d X V x c S , 1 c e b 8 4 3 5 3 a 4 8 0 7 2 8 3 b 0 7 1 9 d 0 7 3 d e f 7 e e a 7 b c 1 a 4 f 4 c 7 5 f c 6 1 9 0 5 0 a d e e 7 0 7 0 1 1 8 1 , 8 c 6 9 5 8 f d 5 7 5 d 3 2 8 9 9 d b 3 e 3 6 2 1 4 e 2 4 d 7 b c c c d c 7 9 2 2 6 5 c f 6 b 7 2 f 9 0 b a 2 b 9 3 d 1 e 7 1 9 , 4 7 3 0 4 4 0 2 2 0 6 6 4 1 5 5 0 f 5 e 3 5 0 6 f a 9 c e 5 d 3 c 0 d 8 a 5 6 8 f 3 0 6 d 6 a 7 a 1 f 2 b 6 7 2 3 e 9 e 4 e c a d 4 0 b d 7 6 d 0 6 0 2 2 0 6 6 c f 6 8 c 4 7 e e 1 6 0 4 b 5 e c 7 2 c 1 a 4 4 2 4 d 7 9 4 0 e e f a a 1 b 5 e 2 a 9 b 3 9 6 c 1 2 c 7 1 a 8 2 8 5 4 5 b 5 0 1 2 1 0 2 d e a b 7 6 c a 9 8 8 4 0 8 c 2 6 e 5 b c 8 2 7 5 d 1 0 0 5 6 1 3 2 2 e b 2 5 e 7 4 3 4 f d b 8 4 b e 9 5 e c c 8 9 5 8 4 3 1 9 , 7 6 a 9 1 4 2 6 f 5 5 d a e e b 9 5 5 7 d 7 a 4 1 e 7 c 7 5 6 d 3 8 3 3 7 9 3 e a 7 0 3 5 4 8 8 a c , 7 6 a 9 1 4 6 e 8 e 0 2 4 9 e d b 3 9 0 3 6 1 3 6 a 4 c 7 3 2 5 f 0 0 0 4 0 0 1 3 7 f 2 a 1 8 8 a c , p a y - t o - p u b k e y - h a s h , p a y - t o - p u b k e y - h a s h , N o n e , N o n e
normal数据: ./dataset/1in2outPN.json
special数据: ./dataset/7_CHT02.json
#word_index {'1': 1, '2': 2, '0': 3, '4': 4, 'a': 5, '8': 6, '7': 7, '3': 8, '6': 9, '9': 10, '5': 11, 'e': 12, 'c': 13, 'b': 14, 'd': 15, 'f': 16, 'o': 17, 'y': 18, 'p': 19, 'h': 20, 'N': 21, 'n': 22, 'k': 23, 't': 24, 'u': 25, 's': 26, 'A': 27, 'E': 28, 'B': 29, 'P': 30, 'J': 31, 'T': 32, 'H': 33, 'D': 34, 'L': 35, 'F': 36, 'M': 37, 'G': 38, 'Z': 39, 'C': 40, 'Q': 41, 'w': 42, 'Y': 43, 'W': 44, 'K': 45, 'g': 46, 'x': 47, 'v': 48, 'U': 49, 'S': 50, 'r': 51, 'z': 52, 'i': 53, 'q': 54, 'm': 55, 'V': 56, 'X': 57, 'R': 58, 'j': 59, 'l': 60}
alldata[1] [2 2 3 ... 0 0 0]
all_label_oh[1008] [0. 1.] 2087
train_data_num: 1669
train_label_num: 1669
val_data_num: 418
val_label_num: 418
2023-09-08 13:17:06.754889: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-08 13:17:06.755245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:06.755384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:06.755421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-08 13:17:06.755454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-08 13:17:06.755465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-08 13:17:06.755475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-08 13:17:06.755485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-08 13:17:06.755495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-08 13:17:06.755505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-08 13:17:06.755516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-08 13:17:06.755875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-08 13:17:06.756064: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-09-08 13:17:06.756288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:17:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:06.756399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.755GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2023-09-08 13:17:06.756424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2023-09-08 13:17:06.756443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-08 13:17:06.756452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-08 13:17:06.756459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-09-08 13:17:06.756468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-09-08 13:17:06.756476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-09-08 13:17:06.756484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2023-09-08 13:17:06.756492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-08 13:17:06.756821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2023-09-08 13:17:06.756857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-09-08 13:17:06.756863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2023-09-08 13:17:06.756869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N 
2023-09-08 13:17:06.756873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N 
2023-09-08 13:17:06.757180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16044 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6)
2023-09-08 13:17:06.757287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 21837 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)
初始lr= 0.005
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 1400)]       0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1400, 300)    18300       input_1[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 1400, 256)    230656      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 1400, 256)    307456      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 1400, 256)    384256      embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 1400, 256)    1536256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 1400, 256)    2304256     embedding[0][0]                  
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 1400, 256)    3072256     embedding[0][0]                  
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 29, 256)      0           conv1d[0][0]                     
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 29, 256)      0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 29, 256)      0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 29, 256)      0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 29, 256)      0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 29, 256)      0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 29, 1536)     0           max_pooling1d[0][0]              
                                                                 max_pooling1d_1[0][0]            
                                                                 max_pooling1d_2[0][0]            
                                                                 max_pooling1d_3[0][0]            
                                                                 max_pooling1d_4[0][0]            
                                                                 max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 44544)        0           concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 44544)        0           flatten[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            89090       dropout[0][0]                    
==================================================================================================
Total params: 7,942,526
Trainable params: 7,924,226
Non-trainable params: 18,300
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2023-09-08 13:17:06.888254: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-09-08 13:17:06.911903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3499910000 Hz
Epoch 1/50
2023-09-08 13:17:07.580212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2023-09-08 13:17:08.232158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2023-09-08 13:17:08.288122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2023-09-08 13:17:12.187325: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
8/8 [==============================] - 14s 839ms/step - loss: 4.2198 - accuracy: 0.4993 - lr: 0.0050 - val_loss: 0.9013 - val_accuracy: 0.4970 - val_lr: 0.0050

Epoch 00001: val_loss improved from inf to 0.90130, saving model to ./checkpoints/model.h5
Epoch 2/50
8/8 [==============================] - 3s 347ms/step - loss: 0.7776 - accuracy: 0.5661 - lr: 0.0050 - val_loss: 0.8953 - val_accuracy: 0.5808 - val_lr: 0.0050

Epoch 00002: val_loss improved from 0.90130 to 0.89527, saving model to ./checkpoints/model.h5
Epoch 3/50
8/8 [==============================] - 3s 343ms/step - loss: 0.6868 - accuracy: 0.6327 - lr: 0.0050 - val_loss: 0.5517 - val_accuracy: 0.7305 - val_lr: 0.0050

Epoch 00003: val_loss improved from 0.89527 to 0.55175, saving model to ./checkpoints/model.h5
Epoch 4/50
8/8 [==============================] - 3s 347ms/step - loss: 0.4599 - accuracy: 0.8418 - lr: 0.0050 - val_loss: 0.4340 - val_accuracy: 0.7784 - val_lr: 0.0050

Epoch 00004: val_loss improved from 0.55175 to 0.43404, saving model to ./checkpoints/model.h5
Epoch 5/50
8/8 [==============================] - 3s 348ms/step - loss: 0.2786 - accuracy: 0.9315 - lr: 0.0050 - val_loss: 0.3180 - val_accuracy: 0.9461 - val_lr: 0.0050

Epoch 00005: val_loss improved from 0.43404 to 0.31802, saving model to ./checkpoints/model.h5
Epoch 6/50
8/8 [==============================] - 3s 347ms/step - loss: 0.1768 - accuracy: 0.9602 - lr: 0.0050 - val_loss: 0.2509 - val_accuracy: 0.9042 - val_lr: 0.0050

Epoch 00006: val_loss improved from 0.31802 to 0.25091, saving model to ./checkpoints/model.h5
Epoch 7/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0885 - accuracy: 0.9841 - lr: 0.0050 - val_loss: 0.2661 - val_accuracy: 0.8982 - val_lr: 0.0050

Epoch 00007: val_loss did not improve from 0.25091
Epoch 8/50
8/8 [==============================] - 3s 347ms/step - loss: 0.0500 - accuracy: 0.9933 - lr: 0.0050 - val_loss: 0.1704 - val_accuracy: 0.9581 - val_lr: 0.0050

Epoch 00008: val_loss improved from 0.25091 to 0.17037, saving model to ./checkpoints/model.h5
Epoch 9/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0285 - accuracy: 0.9985 - lr: 0.0050 - val_loss: 0.1606 - val_accuracy: 0.9641 - val_lr: 0.0050

Epoch 00009: val_loss improved from 0.17037 to 0.16055, saving model to ./checkpoints/model.h5
Epoch 10/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0197 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1710 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00010: val_loss did not improve from 0.16055
Epoch 11/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0099 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1508 - val_accuracy: 0.9521 - val_lr: 0.0050

Epoch 00011: val_loss improved from 0.16055 to 0.15076, saving model to ./checkpoints/model.h5
Epoch 12/50
8/8 [==============================] - 3s 331ms/step - loss: 0.0082 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1680 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00012: val_loss did not improve from 0.15076
Epoch 13/50
8/8 [==============================] - 2s 287ms/step - loss: 0.0056 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1721 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00013: val_loss did not improve from 0.15076
Epoch 14/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0052 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1707 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00014: val_loss did not improve from 0.15076
Epoch 15/50
8/8 [==============================] - 2s 286ms/step - loss: 0.0042 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1727 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00015: val_loss did not improve from 0.15076
Epoch 16/50
8/8 [==============================] - 2s 297ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1716 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00016: val_loss did not improve from 0.15076
Epoch 17/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0031 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1849 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00017: val_loss did not improve from 0.15076
Epoch 18/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0029 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1725 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00018: val_loss did not improve from 0.15076
Epoch 19/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0024 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1811 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00019: val_loss did not improve from 0.15076
Epoch 20/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0020 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1829 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00020: val_loss did not improve from 0.15076
Epoch 21/50
8/8 [==============================] - 3s 334ms/step - loss: 0.0018 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1841 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00021: val_loss did not improve from 0.15076
Epoch 22/50
8/8 [==============================] - 3s 335ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1649 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00022: val_loss did not improve from 0.15076
Epoch 23/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1609 - val_accuracy: 0.9401 - val_lr: 0.0050

Epoch 00023: val_loss did not improve from 0.15076
Epoch 24/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1926 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00024: val_loss did not improve from 0.15076
Epoch 25/50
8/8 [==============================] - 3s 349ms/step - loss: 0.0014 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1658 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00025: val_loss did not improve from 0.15076
Epoch 26/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1910 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00026: val_loss did not improve from 0.15076
Epoch 27/50
8/8 [==============================] - 3s 346ms/step - loss: 0.0012 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1644 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00027: val_loss did not improve from 0.15076
Epoch 28/50
8/8 [==============================] - 3s 349ms/step - loss: 9.7338e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1752 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00028: val_loss did not improve from 0.15076
Epoch 29/50
8/8 [==============================] - 3s 349ms/step - loss: 9.0757e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1825 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00029: val_loss did not improve from 0.15076
Epoch 30/50
8/8 [==============================] - 3s 349ms/step - loss: 9.4980e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1789 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00030: val_loss did not improve from 0.15076
Epoch 31/50
8/8 [==============================] - 3s 349ms/step - loss: 8.8939e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1898 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00031: val_loss did not improve from 0.15076
Epoch 32/50
8/8 [==============================] - 3s 347ms/step - loss: 7.0899e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1815 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00032: val_loss did not improve from 0.15076
Epoch 33/50
8/8 [==============================] - 3s 349ms/step - loss: 7.1663e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1846 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00033: val_loss did not improve from 0.15076
Epoch 34/50
8/8 [==============================] - 3s 348ms/step - loss: 8.8908e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.2071 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00034: val_loss did not improve from 0.15076
Epoch 35/50
8/8 [==============================] - 3s 348ms/step - loss: 0.0010 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1675 - val_accuracy: 0.9401 - val_lr: 0.0050

Epoch 00035: val_loss did not improve from 0.15076
Epoch 36/50
8/8 [==============================] - 3s 350ms/step - loss: 5.4915e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1889 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00036: val_loss did not improve from 0.15076
Epoch 37/50
8/8 [==============================] - 2s 288ms/step - loss: 6.4374e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1693 - val_accuracy: 0.9401 - val_lr: 0.0050

Epoch 00037: val_loss did not improve from 0.15076
Epoch 38/50
8/8 [==============================] - 2s 286ms/step - loss: 5.9847e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1819 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00038: val_loss did not improve from 0.15076
Epoch 39/50
8/8 [==============================] - 2s 293ms/step - loss: 5.0757e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1839 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00039: val_loss did not improve from 0.15076
Epoch 40/50
8/8 [==============================] - 3s 343ms/step - loss: 4.7856e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1881 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00040: val_loss did not improve from 0.15076
Epoch 41/50
8/8 [==============================] - 3s 349ms/step - loss: 4.5855e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1782 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00041: val_loss did not improve from 0.15076
Epoch 42/50
8/8 [==============================] - 3s 348ms/step - loss: 4.3245e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1892 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00042: val_loss did not improve from 0.15076
Epoch 43/50
8/8 [==============================] - 3s 349ms/step - loss: 4.8445e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1748 - val_accuracy: 0.9341 - val_lr: 0.0050

Epoch 00043: val_loss did not improve from 0.15076
Epoch 44/50
8/8 [==============================] - 3s 348ms/step - loss: 4.1556e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1830 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00044: val_loss did not improve from 0.15076
Epoch 45/50
8/8 [==============================] - 3s 319ms/step - loss: 4.6962e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1999 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00045: val_loss did not improve from 0.15076
Epoch 46/50
8/8 [==============================] - 3s 349ms/step - loss: 5.1238e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1671 - val_accuracy: 0.9461 - val_lr: 0.0050

Epoch 00046: val_loss did not improve from 0.15076
Epoch 47/50
8/8 [==============================] - 3s 349ms/step - loss: 3.9140e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1877 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00047: val_loss did not improve from 0.15076
Epoch 48/50
8/8 [==============================] - 3s 350ms/step - loss: 3.4472e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.2061 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00048: val_loss did not improve from 0.15076
Epoch 49/50
8/8 [==============================] - 3s 350ms/step - loss: 3.9144e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1886 - val_accuracy: 0.9281 - val_lr: 0.0050

Epoch 00049: val_loss did not improve from 0.15076
Epoch 50/50
8/8 [==============================] - 3s 347ms/step - loss: 3.5036e-04 - accuracy: 1.0000 - lr: 0.0050 - val_loss: 0.1912 - val_accuracy: 0.9222 - val_lr: 0.0050

Epoch 00050: val_loss did not improve from 0.15076
14/14 [==============================] - 1s 33ms/step
准确率 精度 召回率 平均f1-score
0.9114832535885168
0.9204891592392136
0.9114832535885168
0.9108330985132522


CNN 1D - Train accuracy: 0.995

CNN 1D of Training data
               precision    recall  f1-score   support

           0       1.00      0.99      0.99       802
           1       0.99      1.00      1.00       867

    accuracy                           1.00      1669
   macro avg       1.00      1.00      1.00      1669
weighted avg       1.00      1.00      1.00      1669


CNN 1D - Train Confusion Matrix

 Predicted    0    1
Actuall            
0          795    7
1            1  866

CNN 1D - Test accuracy: 0.911

CNN 1D of Test data
               precision    recall  f1-score   support

           0       0.98      0.83      0.90       204
           1       0.86      0.99      0.92       214

    accuracy                           0.91       418
   macro avg       0.92      0.91      0.91       418
weighted avg       0.92      0.91      0.91       418


CNN 1D - Test Confusion Matrix

 Predicted    0    1
Actuall            
0          170   34
1            3  211
normalpath: ./dataset/1in2outPN.json
specialpath: ./dataset/7_CHT02.json
耗时:151.64783239364624